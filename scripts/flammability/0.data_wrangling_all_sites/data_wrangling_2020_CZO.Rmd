---
title: 'Data Wrangling: czo Flam. Curves (SB Area)'
author: "Indra Boving"
date: "2/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# First, let's get our data how we want it
To load in necessary packages and dataset:
```{r}
library(ggplot2)
library(gapminder)
library(data.table)
library(purrr)
library(naniar)
library(dplyr)
library(tidyverse)
library(ggpubr)
library(simputation)
library(visdat)
library(here)
library(psych)
filter = dplyr::filter #correct filter problem (gets confused with stats::filter)
here = here::here
```

Read in data:

```{r}
raw.data.czo <- read_csv(here("raw-data", "flam.curves.ssCZO.all.data.new.utf8.csv")) 
raw.data.czo %>% 
  filter(lfm > 0) %>%  #remove rows with missing dry weight/neg. lfm
str(raw.data.czo)
```
#Deal with odd values:

First, deal with values that don't make sense due to missingness (for example, if the temp probe turned off and temp.max is listed as 0, or if the weight is listed as 0, or if LFM is negative due to missing dry or wet weight). Do this to manipulated/control variables (weight, temp, mpa) as well as with flammability metrics.

```{r}
raw.data.czo <- raw.data.czo %>% 
  mutate(water.wt = fresh.wt - dry.wt) %>% 
  mutate(ros = ttms/sample.length) 
#str(raw.data.czo)

data.with.na.czo <- raw.data.czo %>% 
  replace_with_na(replace = list(temp.max = c(0, 0.0))) %>% #for missing temp maxs, make NA
  replace_with_na(replace = list(ignition.temp = c(0, 0.0))) %>% #for missing temp at ignition, make NA (all 2016 & 2018 trials)
  replace_with_na(replace = list(start.temp = c(0, 0.0))) %>% #for missing starting temp, make na
  replace_with_na(replace = list(sample.wt = c(0, 0.0))) %>% #for sample weight...
  replace_with_na(replace = list(lfm = c(0.00000))) #for missing lfm (need weird extra 0 types here for some reason?)

#To make any odd values due to lack of ignition 'NA':
data.with.na.czo[c("ttfg", "tti", "fd", "gd", "pfg", "fh", "mpa",  "prop.new", "water.wt", "fresh.wt", "dry.wt", "start.temp")][(data.with.na.czo[c("ttfg", "tti", "fd", "gd", "pfg", "fh", "mpa", "prop.new", "water.wt", "fresh.wt", "dry.wt", "start.temp")] == 0)] <- NA
data.with.na.czo[c("ttfg", "tti", "fd", "gd", "pfg", "gti",  "dry.wt", "water.wt", "fresh.wt", "lfm", "ttms")][(data.with.na.czo[c("ttfg", "tti", "fd", "gd", "pfg", "gti",  "dry.wt", "water.wt", "fresh.wt", "lfm", "ttms")] < 0)] <- NA
data.with.na.czo[c("ttfg", "tti", "fd", "gd", "pfg", "gti")][(data.with.na.czo[c("ttfg", "tti", "fd", "gd", "pfg", "gti")] > 1000)] <- NA
data.with.na.czo[c("water.wt")][(data.with.na.czo[c("water.wt")] > 8 )] <- NA
```

Next, visualize the impact of outliers in LFM with outlierKD function 
(NOTE: outlierKD slightly changed here to NOT require yes/no input when run. Instead, it is performed on a new column to retain unremoved data) 

Details on OutlierKD: "To detect the outliers I use the command boxplot.stats()$out which use the Tukey’s method to identify the outliers ranged above and below the 1.5*IQR." (https://www.r-bloggers.com/2016/04/identify-describe-plot-and-remove-the-outliers-from-the-dataset/)

```{r}
##make column to take out outliers from lfm, while keeping column with original lfms too
data.with.na.czo <- data.with.na.czo %>%
  mutate(lfm.outliers.out = lfm) 

#source("http://goo.gl/UUyEzD") #outlier KD (original function)

    #The following function is derived from outlierKD (from above)
outlierKD2 <- function(dt, var) {
  var_name <- eval(substitute(var),eval(dt))
  tot <- sum(!is.na(var_name))
  na1 <- sum(is.na(var_name))
  m1 <- mean(var_name, na.rm = T)
  par(mfrow=c(2, 2), oma=c(0,0,3,0))
  boxplot(var_name, main="With outliers")
  hist(var_name, main="With outliers", xlab=NA, ylab=NA)
  outlier <- boxplot.stats(var_name)$out
  mo <- mean(outlier)
  var_name <- ifelse(var_name %in% outlier, NA, var_name)
  boxplot(var_name, main="Without outliers")
  hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
  title("Outlier Check", outer=TRUE)
  na2 <- sum(is.na(var_name))
  message("Outliers identified: ", na2 - na1, " from ", tot, " observations")
  message("Proportion (%) of outliers: ", (na2 - na1) / tot*100)
  message("Mean of the outliers: ", mo)
  m2 <- mean(var_name, na.rm = T)
  message("Mean without removing outliers: ", m1)
  message("Mean if we remove outliers: ", m2)
    dt[as.character(substitute(var))] <- invisible(var_name)
    assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
    message("Outliers successfully removed", "\n")
    return(invisible(dt))
}
outlierKD2(data.with.na.czo, lfm.outliers.out) #check for outliers and remove (happens in outliers.out column, lfm column still contains outliers)
```

#Impute missing LFMs based on spp and Mpa: 

Our data are MAR (missing at random) or MCAR (missing completely at random), and can therefore be dealt with in a few ways: complete case analysis, single, or multiple imputation (see: https://doi.org/10.1093/icvts/ivy102 )

Missing values: (Metric:type of missingness)

LFM: MCAR (missing values ARE NOT related to observed values, i.e., missingness is not due to something else that we measured. Missing samples can be treated as random (likelihood of being missing is the same for all missing values).

Flam metrics: MCAR*

*except flame height which is MAR (taller flame heights more likely to be missing if they went out of frame). 

(Note: For MAR, missing values ARE related to observed values, i.e., their missingness could be related to something else that we measured, and could therefor be determined from those values. Improper handling could skew data).

For MCAR, we can use single imputation or multiple imputatation to deal with missings.

Multiple imputation information: https://bookdown.org/mwheymans/bookmi/multiple-imputation.html 

An option is to use MICE: (Multivariate Imputation by Chained Equations; See: https://data.library.virginia.edu/getting-started-with-multiple-imputation-in-r/). This requires that we perform the analysis on each of multiple imputed datasets (usually 5), and then combine the values at the end. 

More information on missing values:

Multiple imputation options in R:
https://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/

Overview on effects of using mean/median/mode: (TL;DR: can reduce variation, but easiest and ok to use if number of missings are small enough not to impact data)


Overview of missingness: 
https://towardsdatascience.com/all-about-missing-data-handling-b94b8b5d2184

Using naniar: (package for visualizing missings)
https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html)

Information on single imputation:  https://thomaselove.github.io/431-notes/missing-data-mechanisms-and-simple-imputation.html#missing-data-mechanisms 

Also see:
Nakagawa, S., & Freckleton, R. P. (2011). Model averaging, missing data and multiple imputation: A case study for behavioural ecology. Behavioral Ecology and Sociobiology, 65(1), 103–116. https://doi.org/10.1007/s00265-010-1044-7

```{r}
#If we want to go the more complicated MICE route, here is the initial dataset:
# library(mice)
# imp <- mice(data.with.na.czo, m=5, maxit=10, method="pmm")
# data.mice <- complete(imp, action = "long", include = TRUE) 
```

Alternatively, we can use single imputation, such as median, mode, robust linear models, or pmm. To do this, the "simputation" package is useful for grouping and visualizing (See: https://cran.r-project.org/web/packages/simputation/vignettes/intro.html)

Paper using rlm for impuatation: https://pubmed.ncbi.nlm.nih.gov/22994905/ 

```{r}
#Visualize:
as_shadow(data.with.na.czo)
aq_shadow <- bind_shadow(data.with.na.czo)
aq_nab <- nabular(data.with.na.czo)
all.equal(aq_shadow, aq_nab)
glimpse(aq_nab)

data.with.na.czo %>%
  bind_shadow() %>%
  ggplot(aes(x = mpa, fill = lfm.outliers.out_NA)) +
  geom_histogram()

NA.pmm <- aq_shadow %>%
  impute_pmm(lfm.outliers.out ~ mpa | spp) %>%
  ggplot(aes(x = mpa,
             y = lfm.outliers.out, 
             colour = lfm.outliers.out_NA, shape = spp)) + 
  geom_point() +
  ggtitle("parametric means matching")
NA.pmm

#imputed missing lfm values:
NA.median <- aq_shadow %>%
  impute_median(lfm.outliers.out ~ spp) %>%
  ggplot(aes(x = mpa,
             y = lfm.outliers.out, 
             colour = lfm.outliers.out_NA,shape = spp)) + 
  geom_point() +
  ggtitle("median")
NA.median
#head(aq_shadow)

NA.rlm <- aq_shadow %>%
  impute_rlm(lfm.outliers.out ~ mpa |spp) %>%
  ggplot(aes(x = mpa,
             y = lfm.outliers.out, 
             colour = lfm.outliers.out_NA,shape = spp)) + 
  geom_point() +
  ggtitle("robust linear model")
NA.rlm
```

Based on the visualizations above and the fact that our data are MCAR, we will use the rlm imputed values for LFM: 

```{r}
#impute rlm for each spp. 
data.with.na.czo <- data.with.na.czo %>%
  mutate(lfm.NAs.imputed = lfm.outliers.out) %>%
  impute_rlm(lfm.NAs.imputed ~ mpa | spp)
```


#Now to add some columns to the dataframe and manipulate some variables:

- Add precip columns with 2 moth and 4 month previous precipitation (from SBBG daily precip. database, see Precip_SB_DATE.Rmd file for tidying that data)
- Proportion ignite columns: for each increase in LFM of 10%, what proportion fo the the attempted burns ignited? 
- Categorical "dry" vs. "wet" vs. "moderate" column for season, based on prior precip and date
- Various categorical groups based on LFM, spp., models, date, etc. used in grouping later on or in creating the above columns. 

```{r}
data <- data.with.na.czo %>% 
  group_by(gr = cut(lfm.NAs.imputed, breaks= seq(0, 400, by = 10))) %>% #create 10 lfm.NAs.imputed segments, indicate these in new column called "gr"
  ungroup() %>% #ungroup - this will stop issues in the future (we can always regroup again)
  group_by(year, model, spp, gr) %>% #create groups based on trial, model, species, and lfm segment
  add_tally %>% #column with n for each of these groups
  ungroup() %>% #ungroup so r doesnt get confused
  unite(model.spp.gr, c("year", "month", "model", "spp", "gr"), remove = FALSE) %>% #create column for each group as above, which will be associated with the n of each group based on the above add_tally step. 
  unite(model.spp.gr.sample, c("year", "month", "model", "spp", "gr", "sample"), remove = FALSE) %>% #create column with group for each indvidual sample (this is a unique ID)
  mutate(individual = model.spp.gr.sample) %>% 
  unite(year.month, c("year", "month"), remove = FALSE) %>% #group for month and year
 #  mutate(precip.2month = year.month) %>%
 # mutate(precip.2mo = recode(precip.2month, "2020_September" = 0.01, "2018_January" = 0.09, "2019_December" = 3.69, "2020_January" = 5.82, "2016_December" = 0.61)) %>%
 #  mutate(season = year.month) %>%
 #  mutate(season = recode(season, "2020_September" = "Dry", "2018_January" = "Dry", "2019_December" = "Wet", "2020_January" = "Wet", "2016_December" = "Dry" )) %>%  #group for month and year
  group_by(model.spp.gr) %>% #group by year, model, spp, group column
  mutate(ignition2 = ignition) %>% 
 # mutate("ignition2 = recode(ignition2, 2 == 1) %>% 
 # mutate(ignition2 = as.numeric(ignition2)) 
  mutate(ignition2 = dplyr::recode(as.double(ignition2), `2` = 1, '3' = 1))

setDT(data)[,total:=sum(ignition2),by=model.spp.gr][] #add column called "total" with the total number of ignitions per group ("sum" works because we have 0s and 1s)

data <-  data %>%
  mutate(prop.ignite = paste0(round(100 * total/n))) %>% #for each group, divide total ignitions ("total" column) by total number burn attempts ("n" column), as a percentage
  ungroup() %>% #ungroup so r doesnt get confused
  #create Rate of Spread column (only relevant for HP metrics, but we'll do it for all and just ignore that column when we do EPI analysis):
  mutate(ros = 10/fd) %>% ##this returns Inf for those missing flame duration (i.e., no burn columns. Shouldnt be an issue when we filter out only those that burned); not relevant for Epiradiator samples, but we'll do it to those anyway and then ignore or filter out that column later. 
  select(-n, -total, -model.spp.gr.sample,-ignition2) #remove columns we aren't interested in anymore

data$prop.ignite <- as.numeric(data$prop.ignite) #Since, otherwise, it would be a character vector
data

hist(data$prop.ignite) #visualize to see if values make sense
```
#Continue adding columns...

- Column labeled "hydration" with break at 60% LFM for dry, 60 - 90% for moderate, and > 100% for hydrated
- Make bins of varying lfm sizes (5, 10, 20)

```{r}
#impute lfm based on relationship with Mpa, grouping by species:
data <- data %>%
  group_by(spp) %>%
#then create bins for LFM, in case we want to compare via bins
  mutate(hydration = cut(lfm.NAs.imputed, breaks = c(0, 60, 90, 400), labels = c("dry", "moderate", "hydrated"))) %>% 
  ungroup() %>%
  group_by(bins5lfm= cut(lfm.NAs.imputed, breaks= seq(0, 400, by = 5))) %>% #create 10 LFM segments, indicate these in new column called "bins5lfm"
  ungroup() %>% #ungroup - this will stop issues in the future (we can always regroup again)
  group_by(bins10lfm= cut(lfm.NAs.imputed, breaks= seq(0, 400, by = 10))) %>% #create 10 LFM segments, indicate these in new column called "bins10lfm"
  ungroup() %>% #ungroup - this will stop issues in the future (we can always regroup again)
  group_by(bins20lfm = cut(lfm.NAs.imputed, breaks= seq(0, 400, by = 20))) %>% #create 20 LFM segments, indicate these in new column called "bins20lfm"
  ungroup() 
```

#Visualize missing weights and temps:

```{r}
vis_miss(data)
gg_miss_var(data, facet = year.month)

data %>% 
  filter(ignition == "1") %>% 
  vis_miss

data %>% 
  filter(ignition == "1") %>% 
  gg_miss_var

ggplot(data, 
       aes(x = lfm.outliers.out, 
           y = dry.wt)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(data, 
       aes(x = lfm.outliers.out, 
           y = fresh.wt)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(data, 
       aes(x = lfm.outliers.out, 
           y = water.wt)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(data, 
       aes(x = lfm.outliers.out, 
           y = sample.wt)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(data, 
       aes(x = lfm.outliers.out, 
           y = start.temp)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

as_shadow(data)
aq_shadow <- bind_shadow(data)
aq_nab <- nabular(data)
all.equal(aq_shadow, aq_nab)
#glimpse(aq_nab)
```
We're not missing a ton of data, so imputing the median should not effect distribution...

```{r include=TRUE}
#view: 
#multi.hist(data[,sapply(data, is.numeric)]) 

#impute values for missing weights:
data <- data %>%
  unite(individual, c("year", "month", "spp", "sample"), remove = FALSE) %>% #create 'individual' column
  dplyr::group_by(model.spp.gr) %>%
  impute_median_at(c("dry.wt", "fresh.wt", "water.wt", "sample.wt")) %>%
  ungroup() %>%
  impute_median_at("start.temp") %>%
  mutate(temp.change = temp.max - start.temp)

range(data$dry.wt)  
range(data$sample.wt) 
range(data$water.wt)
range(data$fresh.wt)
range(data$start.temp)
#...No NAs, good!

#colSums(is.na(data))
```

#Make dry weight columns, etc. for PV comparison: 

(EDIT: PV Sat.weight stuff needs to happen in excel due to need for extrapolation..this is still interesting though)

```{r}
#calculate metrics for weight values (read . as "per", i.e. gdw.gfw is "gram dry weight per gram fresh weight"):
data <- data %>%
  dplyr::mutate(gdw.gfw = dry.wt/fresh.wt) %>%
  dplyr:::mutate(gww.gdw = lfm.NAs.imputed/100) %>%
  dplyr::mutate(gdw.gww = dry.wt/water.wt) %>%
  dplyr::mutate(dw.flam.sample = sample.wt * gdw.gfw) %>%
  dplyr::mutate(ww.flam.sample = sample.wt - dw.flam.sample) %>%
  replace_with_na_at(.vars = c("ww.flam.sample"), condition = ~.x < 0) # oe was below 0 (due to missing lfm), so remove that one 

range(data$gdw.gfw)
range(data$ww.flam.sample)

str(data)
#deal with weight values from the above (should actually not be needed)
data <- data %>%
  #replace_with_na(replace = list(dw.flam.sample = c(0, " ", "  ", "", "   ", "    "))) %>%
  #replace_with_na(replace = list(dw.flam.sample = c(0))) %>% #when dw flam is zero (i.e. missing sample weight or missing lfm)
  #replace_with_na_at(.vars = c("dw.flam.sample"), condition = ~.x < 0) %>%
  dplyr::group_by(model.spp.gr) %>%
  #impute_lm(dw.flam.sample ~ lfm.NAs.imputed) %>%
  impute_median_at("ww.flam.sample") %>%
  dplyr::group_by(model.spp.gr) %>%
  dplyr::group_by(individual) %>% 
  dplyr::mutate(gww.gdw.saturated = max((gww.gdw), na.rm = TRUE)) %>%
  dplyr::mutate(gdw.gww.saturated = min((gdw.gww), na.rm = TRUE)) %>%
  mutate(RWC = (gww.gdw/gww.gdw.saturated)*100) %>%
  mutate(RWD = 100 - RWC) %>%
  mutate(max.mpa.sample = max((mpa), na.rm = TRUE)) %>% 
  select(order(colnames(.))) #make columns in alphabetical order

  str(data)
rwc.data <- data %>% select(individual, year.month, dry.wt, spp, model, lfm.NAs.imputed, RWC, max.mpa.sample, mpa, gww.gdw, gww.gdw.saturated, fresh.wt, dry.wt, site, sample)

str(rwc.data)

write.csv(rwc.data, here("processed-data", "analysis 2.0", "czo_2020_flam_curve_physiological_data.csv"))

rwc.lfm.plot <- rwc.data %>%
  ggplot(aes(x = lfm.NAs.imputed, y = RWC, color = spp)) +
  geom_point()
rwc.lfm.plot
```
##Look at distributions of flammability metrics so we can think about how to deal with NAs, and then deal with them: 

```{r}
ignite.only.hp <- data %>%
  filter(model == "HP") %>% 
  filter(ignition == "1") %>% 
  dplyr::mutate(gti = replace(gti, gti == "0", "0.5")) %>% #replace when gti is zero to .5 seconds, so we can take the log later
  mutate(gti = as.numeric(gti))
```

What does outlierKD think of them? 
```{r}
outlierKD2(ignite_only_hp, tti)
```

```{r}
vis_miss(ignite.only.hp)
gg_miss_var(ignite.only.hp, facet = year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = fh)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = gd)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = temp.change)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = tti)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = gti)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = ros)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = fd)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = prop.ignite)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

ggplot(ignite.only.hp, 
       aes(x = lfm.outliers.out, 
           y = ttfg)) + 
  geom_miss_point() +
  facet_wrap(~year.month)

as_shadow(ignite.only.hp)
aq_shadow <- bind_shadow(ignite.only.hp)
aq_nab <- nabular(ignite.only.hp)
all.equal(aq_shadow, aq_nab)
#glimpse(aq_nab)
```

#Deal with NAs for hotplate:

```{r}
#str(data)
ignite.only.hp %>%
  mutate(gti = as.numeric(gti)) 

ignite.only.hp <- ignite.only.hp %>%
  mutate(fh_nas_imputed = fh) %>% 
  group_by(year.month, spp, bins10lfm) %>% 
#this makes us take the median of based on the species, the model, and the lfm bins (of 10 lfm) the missing value is in. Preserves species differences, and lfm impact. 
  impute_median_at(c("ttfg", "gd", "gti", "fd", "pfg","temp.max", "start.temp", "ros", "ignition.temp", "temp.change", "prop.ignite", "ros", "tti", "fh_nas_imputed")) 
#%>% 
 # impute_lm(fh ~ spp + lfm.NAs.imputed)  #since fh may have gone out of top of frame for some larger flame height trials, use existing information to impute those values (BUT doesn't really matter since so few fh's are actually missing)

colSums(is.na(ignite.only.hp)) #should not be any NAs except in LFM.outliers.out

dist.hp <- ignite.only.hp %>%
  select(fd, fh, gd, gti, pfg, prop.ignite, temp.max, ttfg, tti, temp.change)

multi.hist(dist.hp[,sapply(dist.hp, is.numeric)])
```

#Look at flam characteristics to see if they make sense:

```{r}
range(ignite.only.hp$gti)
range(ignite.only.hp$tti)
range(ignite.only.hp$fh_nas_imputed)
range(ignite.only.hp$fh)
range(ignite.only.hp$gd) #some high glow durations, but that is likely to be expected
range(ignite.only.hp$pfg)
range(ignite.only.hp$ttfg)
range(ignite.only.hp$ros)
range(ignite.only.hp$dw.flam.sample)

ignite.only.hp <- ignite.only.hp %>%
  mutate(flam.index = .45*((387+tti)/(12.5+tti))*exp(fh_nas_imputed/(fh_nas_imputed+55))) #using max tti and max fh, becomes a scale of least (1) to most (20) flammable

range(ignite.only.hp$flam.index)
```

# Normalizing Data - HP only: 

Here we are normalizing by the dry weight of the flammability sample, which was calculated by multiplying the weight of the burned sample by the ratio of dry weight to fresh weight in the samples used for lfm measurements. (Assumptions here: that the ratio of water to dry weight in burned and lfm samples was the same)

```{r}
#colSums(is.na(ignite.only.hp))
#str(ignite.only.hp)
ignite.only.hp <- ignite.only.hp %>%  #Dealing with only EPI trials that ignited (can change later)
  dplyr::mutate(mean.wt = mean(sample.wt, na.rm = TRUE)) %>% #take the mean of all sample weights for each model
  ungroup() %>% 
  mutate_if(is.integer, as.numeric) 

ignite.only.hp$gti <- as.numeric(as.character(ignite.only.hp$gti)) #not sure why this became a character...
#str(ignite.only.hp)

#range(ignite.only.hp$dw.flam.sample) #range gets low for some samples (with very low lfm, maybe?)

distributions.dw <- ignite.only.hp %>%
  ggplot() +
  geom_density(aes(x = dw.flam.sample, color = spp))
distributions.dw 

ignite.only.hp <- ignite.only.hp %>%
  mutate(gti = replace(gti, gti == "0", "0.5")) %>% 
  mutate(gti = as.numeric(gti)) %>%
  mutate("dry.norm.fh" = fh/dw.flam.sample) %>% #create new columns, etc.
  mutate("dry.norm.gd" = gd/dw.flam.sample) %>%
  mutate("dry.norm.fd" = fd/dw.flam.sample) %>%
  mutate("dry.norm.pfg" = pfg/dw.flam.sample) %>%
  mutate("dry.norm.ttfg" = ttfg/dw.flam.sample) %>%
  mutate("dry.norm.tti" = tti/dw.flam.sample) %>% 
  mutate("dry.norm.gti" = gti/dw.flam.sample) %>%
  mutate("temp.change" = temp.max - start.temp) 

colSums(is.na(ignite.only.hp))
#str(ignite.only.hp)
```

```{r}
distributions <- ignite.only.hp %>%
  select(spp, dry.norm.fh, dry.norm.gd, dry.norm.fd, dry.norm.pfg, dry.norm.gti, dry.norm.ttfg, dry.norm.tti) %>%
  gather(-spp, key = "var", value = "value") %>%
  ggplot() +
  geom_density(aes(x = value, color = spp)) +
  facet_wrap(~ var, scales = "free")
distributions +
  ggtitle("Epiradiator")
```

#USE THIS FOR PCA:

Mirroring Max's PCA dataset (Mac_PCA_DATE.Rmd)

```{r}
str(ignite.only.hp)
hp.ignite.only.pca <- ignite.only.hp %>%
  mutate(mpa = mpa * -1) %>%
  # mutate(gti = replace(dry.norm.gti, dry.norm.gti == "0", "0.5")) %>% 
  # select (hydration, spp, sample, model, year.month, mpa, lfm.outliers.out, lfm.NAs.imputed, dw.flam.sample, ww.flam.sample, sample.wt, ttfg, gd, gti, tti, fh, pfg, fd, temp.max, prop.ignite, dry.norm.fh, dry.norm.gd, dry.norm.fd, dry.norm.pfg, dry.norm.gti, dry.norm.ttfg, dry.norm.tti, ros, site, temp.change, flam.index, bins5lfm)  %>%
  # arrange(hydration, spp, sample, model, year.month, mpa, lfm.outliers.out, lfm.NAs.imputed, sample.wt, dw.flam.sample, ww.flam.sample, ttfg, gd, gti, tti, fh, pfg, fd, temp.max, prop.ignite, dry.norm.fh, dry.norm.gd, dry.norm.fd, dry.norm.pfg, dry.norm.gti, dry.norm.ttfg, dry.norm.tti, ros, site, temp.change, flam.index, bins5lfm) %>%
  relocate("hydration")
colSums(is.na(hp.ignite.only.pca))

str(hp.ignite.only.pca) 

#write.csv(x = hp.ignite.only.pca, (here("processed-data", "analysis 2.0", "hp_ignite_only_czo.csv")))

write.csv(x = hp.ignite.only.pca, (here("processed-data", "analysis 2.0", "czo_2020_flam_data_all.csv")))
```



